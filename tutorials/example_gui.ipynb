{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ad5adb",
   "metadata": {},
   "source": [
    "# Graphical user interface quickstart\n",
    "\n",
    "The GUI allows you to load and explore the following types of data:\n",
    "\n",
    "- fMRIprep-processed datasets  \n",
    "- NIFTI files (`.nii`, `.nii.gz`)  \n",
    "- CIFTI files (`.dtseries.nii`)  \n",
    "- Time series data in multiple formats (`.txt`, `.csv`, `.tsv`, `.npy`, `.mat`)  \n",
    "\n",
    "## Downloading data\n",
    "\n",
    "In this tutorial, we will use two examples to demonstrate the GUI.  \n",
    "You can run either (or both) of the following code cells to download sample data, or simply use your own data if you already have some.\n",
    "\n",
    "1) Download a single NIFTI file from the ADHD dataset via nilearn and save it in your working directory.  \n",
    "   (This process may take about a minute. Set `verbose=1` if you would like to see the download progress.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "save_dir = \".\"\n",
    "haxby_data = datasets.fetch_adhd(data_dir=save_dir, n_subjects=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5f05e",
   "metadata": {},
   "source": [
    "2) If you have [datalad](https://www.datalad.org/#install) (and git-annex) installed, you can also fetch fMRIprep-processed data.  \n",
    "   The following code cell downloads one BOLD run together with its confounds file from the  \n",
    "   [Engaging in word recognition elicits highly specific modulations in visual cortex](https://openneuro.org/datasets/ds004489/versions/1.0.0) dataset (ds004489) on OpenNeuro:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacffe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad install https://github.com/OpenNeuroDatasets/ds004489.git\n",
    "!cd ds004489 && datalad get derivatives/sub-114/ses-1/func/sub-114_ses-1_task-catLoc_run-1_space-T1w_desc-preproc_bold.nii.gz && datalad get derivatives/sub-114/ses-1/func/sub-114_ses-1_task-catLoc_run-1_desc-confounds_timeseries.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aca261",
   "metadata": {},
   "source": [
    "## Starting the GUI\n",
    "\n",
    "You can launch the graphical user interface by running `comet-gui` in any terminal where the **comet** environment is available.  \n",
    "For example:\n",
    "\n",
    "\n",
    "```bash\n",
    "(comet) user@pc:~$ comet-gui\n",
    "```\n",
    "\n",
    "As a result, you should be greeted with the data tab of the graphical user interface.\n",
    "\n",
    "<img src=\"../src/comet/data/img/gui/start.jpg\" alt=\"start\" width=\"750\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4345561",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Using a single NIFTI file\n",
    "\n",
    "Click **Load from single file** and select the previously downloaded file:  \n",
    "`adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz`.\n",
    "\n",
    "A panel will appear with several preprocessing options, such as:\n",
    "\n",
    "- Detrending and standardising the data (enabled by default)  \n",
    "- Temporal filtering (requires the TR to be specified)  \n",
    "- Selecting a parcellation scheme  \n",
    "- Discarding initial frames (non-stationary volumes are also detected automatically)  \n",
    "- …  \n",
    "\n",
    "In the example below, we additionally loaded the corresponding confounds file,  \n",
    "selected a subset of regressors (CSF, WM, and translational motion), and applied low-pass filtering at 0.1 Hz.\n",
    "\n",
    "Once your settings are chosen, click **Extract time series** to process and parcellate the data.  \n",
    "The extracted time series will then be available in the **Connectivity Analysis** tab.\n",
    "\n",
    "<img src=\"../src/comet/data/img/gui/single_file.jpg\" alt=\"single\" width=\"750\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dac83b",
   "metadata": {},
   "source": [
    "### Using fMRIprep-processed data\n",
    "\n",
    "Click **Load from fMRIprep outputs** and open the `ds004489/derivatives` folder.  \n",
    "\n",
    "Once the dataset layout is loaded, select:  \n",
    "- Subject: `sub114`  \n",
    "- Task: `catLoc`  \n",
    "- Session: `1`  \n",
    "- Run: `1`  \n",
    "\n",
    "*Note: Although the full dataset structure is initialised, only the data for this specific participant and run was downloaded above.*  \n",
    "\n",
    "The preprocessing options are similar to those for a single NIFTI file.  \n",
    "However, since fMRIprep outputs include several confound regressors, additional cleaning options are available in the **Cleaning strategy** panel.  \n",
    "\n",
    "For example, in the screenshot below we selected `motion`, `wm_csf`, and `high_pass`  \n",
    "\n",
    "This setup regresses out motion, white matter, and cerebrospinal fluid confounds, and applies a high-pass filter.  \n",
    "These strategies follow the implementation documented in [nilearn](https://nilearn.github.io/dev/modules/generated/nilearn.interfaces.fmriprep.load_confounds.html).  \n",
    "You can also hover over the **ℹ️** icons in the GUI to view short explanations.  \n",
    "\n",
    "Finally, click **Extract time series** to process and parcellate the data.  \n",
    "The resulting time series will then appear in the **Connectivity Analysis** tab.\n",
    "\n",
    "<img src=\"../src/comet/data/img/gui/fmriprep.jpg\" alt=\"fmriprep\" width=\"750\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c3046",
   "metadata": {},
   "source": [
    "## Connectivity analysis\n",
    "\n",
    "Once the data has been prepared in the **Data Preparation** tab, connectivity estimation is straightforward: simply choose a method and adjust its parameters as needed.  \n",
    "After the estimation is complete, key metrics can be explored on the right-hand side of the GUI.\n",
    "\n",
    "<img src=\"../src/comet/data/img/gui/sliding_window.jpg\" alt=\"sw\" width=\"750\"/>\n",
    "\n",
    "A particularly useful feature is the ability to compare different connectivity estimates.  \n",
    "For example, you can quickly explore how varying key parameters—such as the window size or window shape—affects sliding-window correlations:\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"../src/comet/data/img/gui/sliding_window2.jpg\" alt=\"sw2\"  width=\"600\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/sliding_window3.jpg\" alt=\"sw3\"  width=\"600\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26770c",
   "metadata": {},
   "source": [
    "### State-based analysis\n",
    "\n",
    "For state-based connectivity analyses, it is often useful to work with data from multiple time series.  \n",
    "In the GUI, this is currently supported via 3D time series arrays of shape: $N_{\\text{subjects}} \\times N_{\\text{timepoints}} \\times N_{\\text{regions}}$.\n",
    "\n",
    "An example of how to create such a file is provided in the [State-based dynamic functional connectivity](example_dfc_state.ipynb) notebook.  \n",
    "When loaded, the data will appear in the GUI as shown below:\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"../src/comet/data/img/gui/state1.jpg\" alt=\"state1\"  width=\"600\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/state2.jpg\" alt=\"state2\"  width=\"600\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2f50c",
   "metadata": {},
   "source": [
    "## Graph analysis\n",
    "\n",
    "Connectivity estimates from the **Connectivity analysis** tab can be directly used for graph analysis.  \n",
    "Alternatively, you may also load connectivity estimates from a file.  \n",
    "\n",
    "The typical workflow is as follows:\n",
    "\n",
    "1. Apply processing steps to the connectivity matrices, such as handling negative values or applying thresholding.  \n",
    "   *Example: In the screenshots below, negative values were removed and matrices were thresholded to 40% density before computing the clustering coefficient.*  \n",
    "2. Estimate graph measures, which are then visualised in the **Graph Measures** tab.  \n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"../src/comet/data/img/gui/graph1.jpg\" alt=\"graph1\" width=\"600\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/graph2.jpg\" alt=\"graph2\" width=\"600\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68787ed4",
   "metadata": {},
   "source": [
    "## Multiverse analysis\n",
    "\n",
    "We generally recommend performing multiverse analyses in code, but the GUI also provides some basic functionality.  \n",
    "As a starting point, you can simply run the multiverse example included with the GUI.\n",
    "\n",
    "1. Click **Create multiverse** to open a file dialog and choose where the multiverse analysis folder should be created.  \n",
    "2. Click **Run multiverse** to execute the analysis. Results will then appear in the **Multiverse Overview** and **Specification Curve** tabs.  \n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"../src/comet/data/img/gui/multiverse1.jpg\" alt=\"mv1\" width=\"600\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/multiverse2.jpg\" alt=\"mv2\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "You can also modify the example:\n",
    "\n",
    "1. For instance, add the number `5` to the `number_2` decision and confirm with the checkmark button.  \n",
    "2. If you don’t mind overwriting previous results, you can skip creating a new multiverse and simply press **Run multiverse** again to update the analysis.  \n",
    "\n",
    "### Running a previously implemented multiverse analysis\n",
    "\n",
    "If you already defined a multiverse analysis in a Jupyter Notebook (e.g. the tutorial multiverse example), you can load it into the GUI via the **Load script** button and continue interacting with it.  \n",
    "Decisions and options can be added or removed through the left-hand panel, while code changes can be directly edited in the right-hand panel.  \n",
    "\n",
    "For example, the autism classification workflow can be loaded from `tutorials/example_mv_abide.ipynb` and explored in the GUI:\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"../src/comet/data/img/gui/multiverse3.jpg\" alt=\"mv3\" width=\"500\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/multiverse4.jpg\" alt=\"mv4\" width=\"500\"/>\n",
    "  <img src=\"../src/comet/data/img/gui/multiverse5.jpg\" alt=\"mv5\" width=\"500\"/>\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfc-multiverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
